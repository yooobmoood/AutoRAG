{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 700 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from dotenv import load_dotenv\n",
    "from konlpy.tag import Kkma\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_teddynote.retrievers import EnsembleRetriever, EnsembleMethod\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "file_path = './data/700words.csv'\n",
    "faiss_index_path = './index/700words_faiss_index.pkl'\n",
    "bm25_index_path = './index/700words_bm25_index.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & Documents\n",
    "def load_csv_as_documents(file_path):\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    documents = []\n",
    "    for i, row in df.iterrows():\n",
    "        title = row['title'].strip() if pd.notna(row['title']) else \"\"\n",
    "        content = row['content'].strip() if pd.notna(row['content']) else \"\"\n",
    "        related_keyword = row['related_keyword'].strip() if pd.notna(row['related_keyword']) else \"\"\n",
    "        \n",
    "        combined_context = f\"단어: {title}\\n설명: {content}\"\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=combined_context,\n",
    "            metadata={\n",
    "                'title': title,\n",
    "                'related_keyword': related_keyword,\n",
    "                'doc_id': i\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = load_csv_as_documents(file_path)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 700개의 문서가 로드되었습니다.\n",
      "--------------------------------------\n",
      "첫 번째 문서 내용: 단어: 가계부실위험지수(HDRI)\n",
      "설명: 가구의 소득 흐름은 물론 금융 및 실물 자산까지 종합적으로 고려하여 가계부채의 부실위험을 평가하는 지표로, 가계의 채무상환능력을 소득 측면\n",
      "--------------------------------------\n",
      "두 번째 문서 내용: 단어: 가계수지\n",
      "설명: 가정에서 일정 기간의 수입(명목소득)과 지출을 비교해서 남았는지 모자랐는지를 표시한 것을 가계수지(household's total income and exp\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(f\"총 {len(documents)}개의 문서가 로드되었습니다.\")\n",
    "print('--------------------------------------')\n",
    "print(f\"첫 번째 문서 내용: {documents[0].page_content[:100]}\")\n",
    "print('--------------------------------------')\n",
    "print(f\"두 번째 문서 내용: {documents[1].page_content[:100]}\")\n",
    "print('--------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kkma 한국어 형태소 분석기\n",
    "kkma = Kkma()\n",
    "\n",
    "def kkma_tokenize(text):\n",
    "    return [token for token in kkma.morphs(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding & Indexing\n",
    "if os.path.exists(faiss_index_path) and os.path.exists(bm25_index_path):\n",
    "    with open(faiss_index_path, 'rb') as f:\n",
    "        faiss_index = pickle.load(f)\n",
    "    with open(bm25_index_path, 'rb') as f:\n",
    "        bm25_kkma = pickle.load(f)\n",
    "else:\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name='paraphrase-multilingual-MiniLM-L12-v2',\n",
    "        model_kwargs={'device': 'mps'},\n",
    "        encode_kwargs={'normalize_embeddings': True},\n",
    "    )\n",
    "\n",
    "    faiss_index = FAISS.from_documents(documents, embedding_model).as_retriever(search_kwargs={\"k\": 5})\n",
    "    with open(faiss_index_path, 'wb') as f:\n",
    "        pickle.dump(faiss_index, f)\n",
    "    \n",
    "    bm25_kkma = BM25Retriever.from_documents(documents, preprocess_func=kkma_tokenize)\n",
    "    bm25_kkma.k = 5\n",
    "    with open(bm25_index_path, 'wb') as f:\n",
    "        pickle.dump(bm25_kkma, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search : CC method\n",
    "weights = [0.93, 0.07]\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[faiss_index, bm25_kkma],\n",
    "    weights=weights,\n",
    "    method=EnsembleMethod.CC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoReranker\n",
    "model_path = \"Dongjin-kr/ko-reranker\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# rerank\n",
    "def rerank(query, retrieved_documents):\n",
    "    pairs = [[query, doc.page_content] for doc in retrieved_documents]\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    with torch.no_grad():\n",
    "        scores = model(**inputs, return_dict=True).logits.view(-1).float()\n",
    "    reranked_docs = sorted(zip(retrieved_documents, scores), key=lambda x: x[1], reverse=True)\n",
    "    return reranked_docs  # (documents, score) return\n",
    "\n",
    "# optimize_context\n",
    "def optimize_context(reranked_docs, max_tokens=6000):\n",
    "    context = \"\"\n",
    "    for doc, score in reranked_docs:\n",
    "        if len(context) + len(doc.page_content) > max_tokens:\n",
    "            break\n",
    "        context += doc.page_content + \"\\n\\n\"\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\", \"retrieved_contents\"],\n",
    "    template=\"\"\"\n",
    "당신의 역할은 경제 용어에 대해 친절하고 쉽게 이해할 수 있는 설명을 제공하는 것입니다.\n",
    "당신은 경제 지식이 없거나 경제 개념을 쉽게 배우고 싶은 사람들을 대상으로 '오늘의 단어' 포스팅을 작성합니다.\n",
    "\n",
    "먼저 단어의 정의를 상세하게 설명해 주고, 일상 생활에 적용할 수 있는 관련 예시를 하나 간단하게 들어주세요.\n",
    "\n",
    "마지막으로 이 용어를 이해하는 것이 왜 중요한지 요약하고 글을 마무리해 주세요.\n",
    "경제 지식이 전혀 없는 사람도 쉽게 이해하고 흥미롭게 읽을 수 있도록 친근하고 쉽게 작성해 주세요.\n",
    "\n",
    "# 주의사항:\n",
    "1. 문서의 내용을 기반으로만 글을 작성하세요. 내용을 지어내거나 사실과 다르게 작성하지 마세요.\n",
    "2. 만약 설명할 수 없는 부분이 있다면, '모르겠습니다'라고 답하세요.\n",
    "3. 모든 제목은 #나 ## 같은 Markdown 표시 없이 굵은 글씨(**)로 나타나야 합니다. 예를 들어'## 경기는'는 '**경기**는'로 표시합니다.\n",
    "4. 본문에는 일반 텍스트 형식을 사용하고, 필요할 경우 단어에만 굵은 글씨를 사용해주세요.\n",
    "5. 제목을 제외하여 주세요.\n",
    "\n",
    "이제 주제에 맞게 블로그 글을 작성해 주세요.\n",
    "질문: {query}\n",
    "단락: {retrieved_contents}\n",
    "답변:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM & Chain\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_with_debug(query, top_k_retrieve=5, top_k_rerank=3):\n",
    "    # Step 1: Retrieve documents\n",
    "    retrieved_documents = hybrid_retriever.invoke(query)\n",
    "    \n",
    "    # 상위 top_k_retrieve 문서만 유지\n",
    "    unique_documents = []\n",
    "    seen = set()\n",
    "    for doc in retrieved_documents:\n",
    "        if doc.page_content not in seen:\n",
    "            unique_documents.append(doc)\n",
    "            seen.add(doc.page_content)\n",
    "        if len(unique_documents) == top_k_retrieve:\n",
    "            break\n",
    "    \n",
    "    print(\"최종 Retrieve 단계에서 검색된 문서:\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    for i, doc in enumerate(unique_documents, 1):\n",
    "        print(f\"문서 {i}:\\n내용: {doc.page_content[:100]}...\\n\")\n",
    "\n",
    "    # Step 2: Rerank documents\n",
    "    reranked_documents = rerank(query, unique_documents)\n",
    "    reranked_documents = reranked_documents[:top_k_rerank]\n",
    "    print(\"\\nReranker를 통해 재정렬된 문서:\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    for i, (doc, score) in enumerate(reranked_documents, 1):\n",
    "        print(f\"문서 {i} (점수: {score}):\\n내용: {doc.page_content[:100]}...\\n\")\n",
    "\n",
    "    # Step 3: 최적화된 컨텍스트 생성 \n",
    "    reranked_contents = optimize_context(reranked_documents)\n",
    "    \n",
    "    # Step 4: Generate response using LLM\n",
    "    response = chain.run({\"query\": query, \"retrieved_contents\": reranked_contents})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Retrieve 단계에서 검색된 문서:\n",
      "--------------------------------------------------\n",
      "문서 1:\n",
      "내용: 단어: 기대인플레이션\n",
      "설명: 기대인플레이션은 향후 물가상승률에 대한 경제주체의 주관적인 전망을 나타내는 개념으로 물가안정을 추구하는 중앙은행이 관심을 기울이고 안정적으로 관리해야 ...\n",
      "\n",
      "문서 2:\n",
      "내용: 단어: 인플레이션\n",
      "설명: 물가수준이 지속적으로 상승하는 현상을 인플레이션이라고 한다. 여기서 물가는 개별 상품의 가격을 평균하여 산출한 물가지수를 의미한다. 인플레이션은 물가상승 ...\n",
      "\n",
      "문서 3:\n",
      "내용: 단어: 근원인플레이션율\n",
      "설명: 근원인플레이션율(core inflation rate)은 물가변동을 초래하는 여러 요인들 가운데 일시적인 공급충격의 영향을 제외한 기조적인 물가상승률을...\n",
      "\n",
      "문서 4:\n",
      "내용: 단어: 디플레이션\n",
      "설명: 물가가 지속적으로 하락하는 현상을 말한다. 디플레이션(deflation) 하에서는 물가상 승률이 마이너스로 하락하는 인플레이션이 나타난다. 디플레이션이 발...\n",
      "\n",
      "문서 5:\n",
      "내용: 단어: 비용인상 인플레이션\n",
      "설명: 재화나 서비스의 생산과 관련하여 투입요소의 비용 상승에 의해 물가가 지속적으로 상승하게 되는 것을 비용인상 인플레이션(cost-push infla...\n",
      "\n",
      "\n",
      "Reranker를 통해 재정렬된 문서:\n",
      "--------------------------------------------------\n",
      "문서 1 (점수: 3.358750820159912):\n",
      "내용: 단어: 인플레이션\n",
      "설명: 물가수준이 지속적으로 상승하는 현상을 인플레이션이라고 한다. 여기서 물가는 개별 상품의 가격을 평균하여 산출한 물가지수를 의미한다. 인플레이션은 물가상승 ...\n",
      "\n",
      "문서 2 (점수: -1.7418097257614136):\n",
      "내용: 단어: 디플레이션\n",
      "설명: 물가가 지속적으로 하락하는 현상을 말한다. 디플레이션(deflation) 하에서는 물가상 승률이 마이너스로 하락하는 인플레이션이 나타난다. 디플레이션이 발...\n",
      "\n",
      "문서 3 (점수: -2.9898006916046143):\n",
      "내용: 단어: 비용인상 인플레이션\n",
      "설명: 재화나 서비스의 생산과 관련하여 투입요소의 비용 상승에 의해 물가가 지속적으로 상승하게 되는 것을 비용인상 인플레이션(cost-push infla...\n",
      "\n",
      "질문: 인플레이션은 무엇인가요?\n",
      "답변: **인플레이션**은 물가수준이 지속적으로 상승하는 현상을 말합니다. 여기서 물가는 특정 상품의 가격을 평균하여 산출한 물가지수를 의미합니다. 즉, 우리가 일상에서 구매하는 물건들의 가격이 전반적으로 오르는 것을 인플레이션이라고 할 수 있습니다. 일반적으로 연간 4~5% 정도의 물가상승률이 관측되면 인플레이션이 발생했다고 판단합니다. 인플레이션이 발생하는 이유는 다양하지만, 경제 성장, 수요 증가, 또는 생산 비용 상승 등이 주요 원인으로 작용할 수 있습니다.\n",
      "\n",
      "예를 들어, 우리가 자주 가는 마트에서 과일 가격이 매년 조금씩 오르는 것을 경험할 수 있습니다. 작년에는 사과 한 개에 1,000원이었는데, 올해는 1,100원이 되었다면, 이는 인플레이션의 한 예입니다. 물가가 오르면 같은 돈으로 살 수 있는 상품의 양이 줄어들기 때문에, 소비자들은 더 많은 돈을 지불해야 원하는 상품을 구매할 수 있습니다.\n",
      "\n",
      "인플레이션을 이해하는 것은 매우 중요합니다. 왜냐하면 인플레이션이 높아지면 우리의 구매력이 줄어들고, 생활비가 증가하게 되기 때문입니다. 또한, 인플레이션이 지속되면 경제 전반에 영향을 미쳐 기업의 생산 비용 증가, 금리 인상 등의 부작용을 초래할 수 있습니다. 따라서 인플레이션을 잘 이해하고 관리하는 것은 개인의 재정 계획뿐만 아니라 국가 경제에도 큰 영향을 미치는 중요한 요소입니다.\n"
     ]
    }
   ],
   "source": [
    "query = \"인플레이션은 무엇인가요?\"\n",
    "response = generate_answer_with_debug(query)\n",
    "\n",
    "# Result\n",
    "print(\"질문:\", query)\n",
    "print(\"답변:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "djanglang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
